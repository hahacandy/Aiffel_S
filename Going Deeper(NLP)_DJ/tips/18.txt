이영빈(대전리드퍼실)  오후 4:13
@channel
오늘 GD-18에 대한 프로젝트 공지를 하도록 하겠습니다.
이번 프로젝트는 아시다시피 GLUE task중 하나인 mnli task를 통해 project를 완성합니다.
그런데... bert를 이용하게 되면 학습이 제대로 되지 않는 현상이 발생합니다. 그래서 bert가 아닌 다른 모델을 사용해서 학습을 시켜야 합니다. AIFFEL 대전에 패스트 페이퍼 칸을 가면 다양한 모델들이 들어가 있습니다. 또 다른 방식으로는 https://huggingface.co/models 해당 url에서 tensorflow와 해당 모델에 대한 task로 분류하면 모델들이 나옵니다. 거기서 모델을 하나 선택하시면 됩니다.https://huggingface.co/transformers/index.html 에서 모델을 선택해서 tokenizer와 해당 모델에 대한 task + 모델을 불러오시면 됩ㄴ니다.
루브릭 같은 경우 3번같은 경우 accuracy 80%로 되어 있는데 해당 모델이 학습이 되었다고 판단되면 별점을 획득할 수 있게끔 진표님과 합의했습니다.
huggingface.co
Hugging Face – The AI community building the future.
We’re on a journey to advance and democratize artificial intelligence through open source and open science. (59kB)
https://huggingface.co/models

huggingface.co
Transformers
State-of-the-art Natural Language Processing for Pytorch and TensorFlow 2.0. :안아주는_얼굴: Transformers (formerly known as pytorch-transformers and pytorch-pretrained-be... (34kB)
https://huggingface.co/transformers/index.html
