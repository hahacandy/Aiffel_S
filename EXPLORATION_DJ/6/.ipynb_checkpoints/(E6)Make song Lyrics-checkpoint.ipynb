{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "nervous-revelation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re                  # 정규표현식을 위한 Regex 지원 모듈 (문장 데이터를 정돈하기 위해) \n",
    "import tensorflow as tf    # 대망의 텐서플로우!\n",
    "import numpy as np         # 변환된 문장 데이터(행렬)을 편하게 처리하기 위해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acquired-reverse",
   "metadata": {},
   "source": [
    "# データを持って来てモデル訓練できるように変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "decimal-nowhere",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " ['\"Don\\'t worry about a thing,', \"'Cause every little thing gonna be all right.\", 'Singin\\': \"Don\\'t worry about a thing,']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "txt_file_path = 'lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "vietnamese-light",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip()       # 소문자로 바꾸고 양쪽 공백을 삭제\n",
    "  \n",
    "    # 아래 3단계를 거쳐 sentence는 스페이스 1개를 delimeter로 하는 소문자 단어 시퀀스로 바뀝니다.\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)        # 패턴의 특수문자를 만나면 특수문자 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)                  # 공백 패턴을 만나면 스페이스 1개로 치환\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)  # a-zA-Z?.!,¿ 패턴을 제외한 모든 문자(공백문자까지도)를 스페이스 1개로 치환\n",
    "\n",
    "    sentence = sentence.strip()\n",
    "\n",
    "    sentence = '<start> ' + sentence + ' <end>'      # 이전 스텝에서 본 것처럼 문장 앞뒤로 <start>와 <end>를 단어처럼 붙여 줍니다\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))   # 이 문장이 어떻게 필터링되는지 확인해 보세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-personality",
   "metadata": {},
   "source": [
    "txtを一列ごとに読んで必要な単語だけセーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fancy-mobility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> don t worry about a thing , <end>',\n",
       " '<start> cause every little thing gonna be all right . <end>',\n",
       " '<start> singin don t worry about a thing , <end>',\n",
       " '<start> cause every little thing gonna be all right ! rise up this mornin , <end>',\n",
       " '<start> smiled with the risin sun , <end>',\n",
       " '<start> three little birds <end>',\n",
       " '<start> perch by my doorstep <end>',\n",
       " '<start> singin sweet songs <end>',\n",
       " '<start> of melodies pure and true , <end>',\n",
       " '<start> sayin , this is my message to you ou ou singin don t worry bout a thing , <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    if len(sentence) == 0: continue\n",
    "        \n",
    "    corpus.append(preprocess_sentence(sentence))\n",
    "        \n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otherwise-evolution",
   "metadata": {},
   "source": [
    "文章の内容がある場合のみセーブ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "latest-helping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    2    37    15 ...     0     0     0]\n",
      " [    2    67   133 ...     0     0     0]\n",
      " [    2  1541    37 ...     0     0     0]\n",
      " ...\n",
      " [    2     5    22 ...     0     0     0]\n",
      " [    2    24     6 ...     0     0     0]\n",
      " [    2    67 10154 ...     0     0     0]] <keras_preprocessing.text.Tokenizer object at 0x7f8bd6186250>\n"
     ]
    }
   ],
   "source": [
    "def tokenize(corpus):\n",
    "    # 텐서플로우에서 제공하는 Tokenizer 패키지를 생성\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,  # 전체 단어의 개수 \n",
    "        filters='',    # 별도로 전처리 로직을 추가할 수 있습니다. 이번에는 사용하지 않겠습니다.\n",
    "        oov_token=\"<unk>\"  # out-of-vocabulary, 사전에 없었던 단어는 어떤 토큰으로 대체할지\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)   # 우리가 구축한 corpus로부터 Tokenizer가 사전을 자동구축하게 됩니다.\n",
    "    \n",
    "    \n",
    "    # 이후 tokenizer를 활용하여 모델에 입력할 데이터셋을 구축하게 됩니다.\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   # tokenizer는 구축한 사전으로부터 corpus를 해석해 Tensor로 변환합니다.\n",
    "    \n",
    "    # tokenの数が１５個超過は捨てる\n",
    "    temp = []\n",
    "    for item in tensor:\n",
    "        if len(item) > 15: continue\n",
    "        temp.append(item)\n",
    "        \n",
    "        \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞추기 위한 padding  메소드를 제공합니다.\n",
    "    # maxlen의 디폴트값은 None입니다. 이 경우 corpus의 가장 긴 문장을 기준으로 시퀀스 길이가 맞춰집니다.\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(temp, padding='post') \n",
    "    \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-sydney",
   "metadata": {},
   "source": [
    "持ってきた歌詞たちをtoken化する   \n",
    "12000個の単語のみ、一つの文章が１５個を超えたら捨てる   \n",
    "そしてvetor化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "based-catalyst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2  37  15 717 113   9 180   4   3   0   0   0   0   0]\n",
      "[ 37  15 717 113   9 180   4   3   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "src_input = tensor[:, :-1]  # tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성합니다. 마지막 토큰은 <end>가 아니라 <pad>일 가능성이 높습니다.\n",
    "tgt_input = tensor[:, 1:]    # tensor에서 <start>를 잘라내서 타겟 문장을 생성합니다.\n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-immune",
   "metadata": {},
   "source": [
    "これをする理由は   \n",
    "src_inputのあとはどんな単語が出てばいいのかのため   \n",
    "   \n",
    "src_input[0]が出た場合はtgt_input[0]が出てほしい事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "constant-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, \n",
    "                                                                tgt_input, \n",
    "                                                                test_size=0.2,\n",
    "                                                                shuffle=True)\n",
    "\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "hidden-cloud",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124981, 14)\n",
      "Target Train: (124981, 14)\n"
     ]
    }
   ],
   "source": [
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-bahrain",
   "metadata": {},
   "source": [
    "# モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "steady-cleaners",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(src_input)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(src_input) // BATCH_SIZE\n",
    "\n",
    "VOCAB_SIZE = tokenizer.num_words + 1    # tokenizer가 구축한 단어사전 내 12000개와, 여기 포함되지 않은 0:<pad>를 포함하여 12001개\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train)).shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reflected-overhead",
   "metadata": {},
   "source": [
    "BUFFER_SIZEこれは多分c言語なのですることだと思います   \n",
    "source,targetデータをtf.data.Datasetに入れて使います"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "integrated-arthritis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super(TextGenerator, self).__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256\n",
    "hidden_size = 1024\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
    "\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-victorian",
   "metadata": {},
   "source": [
    "これは一体なんですかと思ったんですが   \n",
    "多分こういうやってモデル作成できますよとの事を教えてくれるだと思います   \n",
    "   \n",
    "embedding_size, hidden_sizeはデータ数が多ければこれも多くなるらしいです   \n",
    "そしてデータ数が少ない場合これを多くしたら良くないそうです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ceramic-vocabulary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [-1.7840360e-04,  1.6349106e-04, -2.5762719e-04, ...,\n",
       "          6.4840657e-04,  7.5954106e-04,  5.2867682e-07],\n",
       "        [-1.6594067e-04,  6.6412892e-04, -8.6580032e-05, ...,\n",
       "          8.3341182e-04,  8.4973319e-04,  3.5475849e-04],\n",
       "        ...,\n",
       "        [-1.4341930e-03, -3.9288329e-04,  4.3908431e-04, ...,\n",
       "          3.5816722e-04,  1.3520631e-03, -4.5176566e-04],\n",
       "        [-1.8607904e-03, -9.0951764e-04,  5.0287176e-04, ...,\n",
       "          3.7961412e-04,  1.4407263e-03, -3.4966820e-04],\n",
       "        [-2.2876437e-03, -1.3912711e-03,  5.5235997e-04, ...,\n",
       "          3.8934551e-04,  1.5073174e-03, -2.7405837e-04]],\n",
       "\n",
       "       [[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [ 7.8392870e-05, -8.9513400e-05, -1.2877352e-04, ...,\n",
       "          7.0505455e-04,  6.5151037e-04,  2.0679245e-04],\n",
       "        [ 3.3474661e-04, -1.1563924e-04, -1.5475236e-04, ...,\n",
       "          7.3721370e-04,  8.6449896e-04,  3.5465267e-04],\n",
       "        ...,\n",
       "        [-3.1204833e-04, -7.8735361e-04,  6.2571722e-05, ...,\n",
       "          2.6252863e-04,  1.2517117e-03,  9.1155333e-04],\n",
       "        [-7.7561097e-04, -1.1995742e-03,  1.6094121e-04, ...,\n",
       "          2.3779542e-04,  1.3838853e-03,  8.6148304e-04],\n",
       "        [-1.2637425e-03, -1.6059348e-03,  2.4380034e-04, ...,\n",
       "          2.0901398e-04,  1.4878766e-03,  7.8282709e-04]],\n",
       "\n",
       "       [[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [-5.4307417e-05, -3.1368012e-04, -4.3033980e-04, ...,\n",
       "          7.3134719e-04,  6.2563864e-04,  1.4853051e-04],\n",
       "        [-4.4877957e-05, -4.1827341e-04, -6.2508578e-04, ...,\n",
       "          9.7563799e-04,  6.2344526e-04,  1.0933540e-04],\n",
       "        ...,\n",
       "        [-7.7309151e-04, -1.6974831e-03, -9.9906138e-05, ...,\n",
       "          5.1335344e-04,  7.3601794e-04, -6.4657343e-04],\n",
       "        [-9.7514293e-04, -1.7679909e-03,  7.1129267e-05, ...,\n",
       "          4.3944520e-04,  1.0360772e-03, -5.2912213e-04],\n",
       "        [-1.2412796e-03, -1.9089652e-03,  2.1041042e-04, ...,\n",
       "          4.0537328e-04,  1.3142977e-03, -3.8877444e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [-8.1757760e-05, -2.2043755e-04, -5.1744119e-04, ...,\n",
       "          2.5280387e-04,  6.2551134e-04,  1.4561119e-04],\n",
       "        [-4.6293011e-05, -4.3711462e-04, -7.1605732e-04, ...,\n",
       "          2.7141243e-04,  6.3500827e-04,  3.1004785e-04],\n",
       "        ...,\n",
       "        [-5.7574757e-04, -9.7695843e-04,  6.0325192e-04, ...,\n",
       "          6.3835709e-05,  3.2613261e-05, -3.2959866e-05],\n",
       "        [-9.2719845e-04, -1.1143070e-03,  8.0573728e-04, ...,\n",
       "          2.2082379e-04,  3.6502842e-04,  5.2892243e-05],\n",
       "        [-1.3240592e-03, -1.3284124e-03,  9.5131260e-04, ...,\n",
       "          3.5787409e-04,  6.6292851e-04,  1.3818608e-04]],\n",
       "\n",
       "       [[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [-1.9485378e-04, -2.6908523e-04, -3.0093838e-04, ...,\n",
       "          6.5722334e-04,  2.7815191e-04,  2.0639482e-04],\n",
       "        [-5.8031099e-05, -3.0120750e-04, -4.4386782e-04, ...,\n",
       "          7.0366048e-04, -3.7584352e-05,  7.0588416e-05],\n",
       "        ...,\n",
       "        [ 1.4346130e-03,  4.1147953e-04,  9.1376400e-04, ...,\n",
       "          1.2753188e-03,  4.3502855e-04, -3.4671708e-04],\n",
       "        [ 1.0514472e-03,  1.5581229e-04,  1.0106068e-03, ...,\n",
       "          1.1947211e-03,  5.7048001e-04, -2.7611983e-04],\n",
       "        [ 5.3868227e-04, -1.9902240e-04,  1.0786444e-03, ...,\n",
       "          1.0840119e-03,  7.3777750e-04, -1.8128952e-04]],\n",
       "\n",
       "       [[-8.3784653e-05, -9.3008959e-05, -1.9470202e-04, ...,\n",
       "          3.2312921e-04,  3.9776723e-04,  1.8253100e-04],\n",
       "        [-8.2687082e-05, -1.6466873e-04, -1.3794900e-04, ...,\n",
       "          4.0530018e-04,  7.1758404e-04,  3.5858343e-04],\n",
       "        [-1.7395553e-04, -3.8368284e-04, -1.4513724e-04, ...,\n",
       "          3.7517044e-04,  6.3618750e-04,  2.9377636e-04],\n",
       "        ...,\n",
       "        [-6.6409103e-04, -4.9316889e-04,  1.2506209e-03, ...,\n",
       "          1.0997767e-03,  1.3811529e-03, -4.8567489e-04],\n",
       "        [-8.9846598e-04, -7.1002281e-04,  1.1896323e-03, ...,\n",
       "          1.0336910e-03,  1.5601772e-03, -5.0265825e-04],\n",
       "        [-1.1968487e-03, -9.9676929e-04,  1.1098686e-03, ...,\n",
       "          9.6966047e-04,  1.7060058e-03, -4.7766184e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "model(src_sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automated-marsh",
   "metadata": {},
   "source": [
    "take(1)これをする理由は   \n",
    "https://stackoverflow.com/questions/55435784/what-does-example-mnist-train-take1   \n",
    "tupleデータを得るためらしいです"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "curious-constitution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 29,012,961\n",
      "Trainable params: 29,012,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-accuracy",
   "metadata": {},
   "source": [
    "# モデル訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "theoretical-david",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "\n",
    "# the save point\n",
    "checkpoint_dir = 'lyricist/models/'\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "print(\"✅\")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "copyrighted-voluntary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n",
      "Epoch 1/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 3.4889\n",
      "Epoch 00001: loss improved from inf to 3.48887, saving model to lyricist/models/\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 3.4889\n",
      "Epoch 2/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 3.0304\n",
      "Epoch 00002: loss improved from 3.48887 to 3.03039, saving model to lyricist/models/\n",
      "488/488 [==============================] - 66s 135ms/step - loss: 3.0304\n",
      "Epoch 3/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.8658\n",
      "Epoch 00003: loss improved from 3.03039 to 2.86578, saving model to lyricist/models/\n",
      "488/488 [==============================] - 65s 133ms/step - loss: 2.8658\n",
      "Epoch 4/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.7419\n",
      "Epoch 00004: loss improved from 2.86578 to 2.74191, saving model to lyricist/models/\n",
      "488/488 [==============================] - 65s 133ms/step - loss: 2.7419\n",
      "Epoch 5/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.6370\n",
      "Epoch 00005: loss improved from 2.74191 to 2.63700, saving model to lyricist/models/\n",
      "488/488 [==============================] - 64s 131ms/step - loss: 2.6370\n",
      "Epoch 6/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.5420\n",
      "Epoch 00006: loss improved from 2.63700 to 2.54204, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 126ms/step - loss: 2.5420\n",
      "Epoch 7/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.4538\n",
      "Epoch 00007: loss improved from 2.54204 to 2.45382, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 2.4538\n",
      "Epoch 8/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.3715\n",
      "Epoch 00008: loss improved from 2.45382 to 2.37153, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 2.3715\n",
      "Epoch 9/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.2945\n",
      "Epoch 00009: loss improved from 2.37153 to 2.29446, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 2.2945\n",
      "Epoch 10/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.2208\n",
      "Epoch 00010: loss improved from 2.29446 to 2.22078, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 2.2208\n",
      "Epoch 11/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.1507\n",
      "Epoch 00011: loss improved from 2.22078 to 2.15065, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 126ms/step - loss: 2.1507\n",
      "Epoch 12/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.0830\n",
      "Epoch 00012: loss improved from 2.15065 to 2.08301, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 2.0830\n",
      "Epoch 13/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 2.0172\n",
      "Epoch 00013: loss improved from 2.08301 to 2.01717, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 126ms/step - loss: 2.0172\n",
      "Epoch 14/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.9549\n",
      "Epoch 00014: loss improved from 2.01717 to 1.95492, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 1.9549\n",
      "Epoch 15/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.8945\n",
      "Epoch 00015: loss improved from 1.95492 to 1.89450, saving model to lyricist/models/\n",
      "488/488 [==============================] - 61s 125ms/step - loss: 1.8945\n",
      "Epoch 16/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.8359\n",
      "Epoch 00016: loss improved from 1.89450 to 1.83590, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 1.8359\n",
      "Epoch 17/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.7794\n",
      "Epoch 00017: loss improved from 1.83590 to 1.77940, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 1.7794\n",
      "Epoch 18/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.7250\n",
      "Epoch 00018: loss improved from 1.77940 to 1.72502, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 1.7250\n",
      "Epoch 19/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.6719\n",
      "Epoch 00019: loss improved from 1.72502 to 1.67185, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 128ms/step - loss: 1.6719\n",
      "Epoch 20/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.6206\n",
      "Epoch 00020: loss improved from 1.67185 to 1.62062, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 1.6206\n",
      "Epoch 21/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.5709\n",
      "Epoch 00021: loss improved from 1.62062 to 1.57088, saving model to lyricist/models/\n",
      "488/488 [==============================] - 62s 127ms/step - loss: 1.5709\n",
      "Epoch 22/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.5229\n",
      "Epoch 00022: loss improved from 1.57088 to 1.52290, saving model to lyricist/models/\n",
      "488/488 [==============================] - 66s 136ms/step - loss: 1.5229\n",
      "Epoch 23/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.4772\n",
      "Epoch 00023: loss improved from 1.52290 to 1.47721, saving model to lyricist/models/\n",
      "488/488 [==============================] - 63s 129ms/step - loss: 1.4772\n",
      "Epoch 24/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.4339\n",
      "Epoch 00024: loss improved from 1.47721 to 1.43387, saving model to lyricist/models/\n",
      "488/488 [==============================] - 64s 131ms/step - loss: 1.4339\n",
      "Epoch 25/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.3922\n",
      "Epoch 00025: loss improved from 1.43387 to 1.39225, saving model to lyricist/models/\n",
      "488/488 [==============================] - 63s 129ms/step - loss: 1.3922\n",
      "Epoch 26/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.3526\n",
      "Epoch 00026: loss improved from 1.39225 to 1.35256, saving model to lyricist/models/\n",
      "488/488 [==============================] - 64s 132ms/step - loss: 1.3526\n",
      "Epoch 27/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.3150\n",
      "Epoch 00027: loss improved from 1.35256 to 1.31505, saving model to lyricist/models/\n",
      "488/488 [==============================] - 63s 129ms/step - loss: 1.3150\n",
      "Epoch 28/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.2804\n",
      "Epoch 00028: loss improved from 1.31505 to 1.28036, saving model to lyricist/models/\n",
      "488/488 [==============================] - 60s 123ms/step - loss: 1.2804\n",
      "Epoch 29/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.2468\n",
      "Epoch 00029: loss improved from 1.28036 to 1.24681, saving model to lyricist/models/\n",
      "488/488 [==============================] - 63s 130ms/step - loss: 1.2468\n",
      "Epoch 30/30\n",
      "488/488 [==============================] - ETA: 0s - loss: 1.2157\n",
      "Epoch 00030: loss improved from 1.24681 to 1.21571, saving model to lyricist/models/\n",
      "488/488 [==============================] - 63s 129ms/step - loss: 1.2157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8bd3b55dd0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset,\n",
    "          epochs=30,\n",
    "         callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "several-hamilton",
   "metadata": {},
   "source": [
    "そして訓練します   \n",
    "embedding_size, hidden_size数値を変えてみたかったんですが   \n",
    "これだけでも時間がかかりすぎて勇気が出なかったんです   \n",
    "   \n",
    "前回学んだモデルセーブ機能を使ってみたり"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hispanic-plane",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 일단 텐서로 변환합니다.\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    # 텍스트를 실제로 생성할때는 루프를 돌면서 단어 하나씩 생성해야 합니다. \n",
    "    while True:\n",
    "        predict = model(test_tensor)  # 입력받은 문장의 텐서를 입력합니다. \n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1]   # 우리 모델이 예측한 마지막 단어가 바로 새롭게 생성한 단어가 됩니다. \n",
    "\n",
    "        # 우리 모델이 새롭게 예측한 단어를 입력 문장의 뒤에 붙여 줍니다. \n",
    "        test_tensor = tf.concat([test_tensor, \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "\n",
    "        # 우리 모델이 <end>를 예측했거나, max_len에 도달하지 않았다면  while 루프를 또 돌면서 다음 단어를 예측해야 합니다.\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # 생성된 tensor 안에 있는 word index를 tokenizer.index_word 사전을 통해 실제 단어로 하나씩 변환합니다. \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated   # 이것이 최종적으로 모델이 생성한 자연어 문장입니다.\n",
    "\n",
    "\n",
    "print(\"clear\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "major-michael",
   "metadata": {},
   "source": [
    "入力した文字を基に次の文字を探して出します   \n",
    "次の文字がないとかmax_len=20を超えた場合returnして文章を出してくれます"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-headquarters",
   "metadata": {},
   "source": [
    "# どれだけ予測できるのかを見ます"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "square-cowboy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2 = tf.data.Dataset.from_tensor_slices((enc_val, dec_val)).shuffle(BUFFER_SIZE)\n",
    "dataset2 = dataset2.batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "proof-convergence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "488/488 [==============================] - 23s 48ms/step - loss: 1.1581\n",
      "✅\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(dataset)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "mighty-tutorial",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss value: 1.158\n"
     ]
    }
   ],
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-ceiling",
   "metadata": {},
   "source": [
    "# 実際に使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "parental-render",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i am the one who loves <end> '"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i am\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-radical",
   "metadata": {},
   "source": [
    "# ここからは私なりのテスト"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "planned-recovery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f8bc8374910>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(checkpoint_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-supervision",
   "metadata": {},
   "source": [
    "セーブしたモデルを持ってくる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dress-corrections",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i am the one who loves <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> i am\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-repair",
   "metadata": {},
   "source": [
    "良くできる"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "aiffel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
